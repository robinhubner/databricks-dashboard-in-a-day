# The job that triggers dab_data_engineering_etl.

resources:
  jobs:
    dab_data_engineering_job:
      name: dab_data_engineering_job

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      #email_notifications:
      #  on_failure:
      #    - your_email@example.com

      tasks:
        - task_key: refresh_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.dab_data_engineering_etl.id}
